% Strategies and Structures for Improving Data Use - An SEA Perspective
% Presentation to the SDP Summer Institute for Leadership in Analytics August 6th-8th 2012
% Jared Knowles, Policy Research Advisor at Wisconsin Department of Public Instruction


```{r setuph, include=FALSE}
# set global chunk options
opts_chunk$set(fig.path='figure/slides-', cache.path='cache/slides-',fig.width=8,fig.height=6,message=FALSE,error=FALSE,warning=FALSE,echo=TRUE,size='tiny',dev='svg',out.width='600px',out.height='350px')
source('ggplot2themes.R')
load('data/smalldata.rda')
```

# The Big Questions
- How do extract meaning from administrative data systems?
- Can we do data analysis fast enough to inform decisions and improve outcomes?
- Can we produce analyses that are **approachable** to policy makers the public _so that they galvanize change_?
- Can we do this under time and capacity constraints in a way that is rigorous, valid, and accurate?

<p align="center"><img src="img/dpilogo.png" height="81" width="138"></p>


# Meet the Inference Tree
```{r treedata,fig.width=13,fig.height=8,out.width='900px',out.height='600px',echo=FALSE}
library(partykit)
mypar<-ctree_control(testtype='Bonferroni',mincriterion=0.99)
mytree<-ctree(mathSS~race+econ+ell+disab+sch_fay+dist_fay+attday+readSS,
              data=subset(df,grade==3))
plot(mytree)
```

# What is an inference tree?
- An inference tree isa way of dividing data into meaningful groups
- It is an algorithm that splits data by groups searching for the most meaningful and significant splits among grouping variables
- This is a way to identify meaningfully large groups with differing performance
- Useful for exploring policy opportunities

# How can it be used?
- A little R code
- A little explanation
- A good dataset with good variables that are meaningful
- The good news is most states have all of this!


# The R Code
- This looks remarkably like Stata code, but the plot drawing is much simpler in many cases

```{r treedatacode,eval=FALSE,echo=TRUE}
library(partykit)
mypar<-ctree_control(testtype='Bonferroni',mincriterion=0.99)
mytree<-ctree(mathSS~race+econ+ell+disab+sch_fay+dist_fay+attday+readSS,
              data=subset(df,grade==3))
plot(mytree)
```

# Using Graphics To Tell a Story: Maps

<p align="center"><img src="img/evenFRLmap.gif" height="640" width="550"></p>


# Using Graphics to Tell a Story: Animations

<p align="center"><img src="img/TESTstuplot.gif" height="650" width="860"></p>

# R Code
- This is not all the R code, animations are a **bit** more complicated
- This gives a feel for the structure
- The advantage is that they can be shared and reproduced like the SDP Toolkit graphics

```{r eval=FALSE}
# Draw subset
library(ggplot2)
for(i in 1:100){
  mysub<-subset(studata,math_percentile==i)
  png(file="frame",i,".png",width=1000,height=750)
  qplot(grade,mathSS,data=mysub,geom='lines',group=stuid,alpha=I(.2))+prof_poly()+
    stat_summary(median,data=mysub,color="gold",size=I(1.04))+geom_text(Labels)
  dev.off()
}

```

# Demonstrate Distributions Linking Tests

<p align="center"><img src="img/testaniCUML.gif" height="650" width="860"></p>


# This is different than research
- First, it is using the population data for what it should be used for
- Second, it's free and easy to implement
- Third, it's useful for questions policy makers might be eager to know--where should we focus our limited resources?
- So, how do we do it?

# Ask Jen
- Every agency has someone who gets these requests, and that someone is **overworked**
<p align="center"><img src="img/jen1.jpg" height="570" width="700"></p>


# The Problem?
- Jen doesn't scale
- We don't have enough Jen's

<p align="center"><img src="img/jen.jpg" height="570" width="700"></p>


# Policy Relevant Research is the Answer
John Tukey said:

> An approximate answer to the right problem
> is worth a good deal more than the exact 
> answer to an approximate problem

- This is what policy relevant research is about

# Fast
<p align="center"><img src="img/fast.jpg" height="612" width="720"></p>


# Focused
<p align="center"><img src="img/laserfocus.jpg" height="612" width="720"></p>

# Approximate
<p align="center"><img src="img/horseshoes2.jpg" height="612" width="720"></p>

# Policy relevant research is everywhere
- COMPSTAT used by police departments around the world with an estimated 90% of large US police deparments implementing it [http://www.policefoundation.org/pdf/growthofcompstat.pdf](http://www.policefoundation.org/pdf/growthofcompstat.pdf)
- A/B testing at [Khan Academy](http://www.khanacademy.org/about/blog/post/22599533318/trying-out-new-features), Amazon, Netflix, and others
- Financial services, stock trading, etc.
- ROI on capital investments in municipal works
- **Teaching** is all about quick and focused research into what works through benchmark assessments and feedback

# Getting Value from Data
- Over $500 millon spent on building Statewide Longitudinal Data Sysems at SEAs [DQC](http://www.dataqualitycampaign.org/resources/details/1051)
- Exponential increase in the amount of data collected
- Constrained resources, tightened budgets, lack of time
- Skills in program areas don't align with data needs
- Researcher contracting does not scale, does not work on this timeline, and does not answer the question of the moment

# How to do this?
- Everyone at an SEA has a ton of work and data analysis is often viewed as a luxury
- Additionally, work has to be done **efficiently**, **tranparently**, and **reproducibly** to be valid
- This is expensive in terms of time, money, and management resources
- Analyses that are done are done ad hoc and disconnected from a cohesive strategy
- They are **poorly documented**
- Done in disparate and proprietary toolsets
- Unable to be reproduced with updated data
- **Knowledge is lost, not accumulated**

- What are some solutions?

# My Favorite
<p align="center"><img src="img/frustration.jpg" height="612" width="720"></p>

# Wisconsin's Solution

### R

<p align="center"><img src="img/Rlogo.png" height="500" width="600"></p>


# R is
- Free and open source
- Extensible
- Reproducible 
- Scriptable
- Can be integrated into operational systems
- A gateway to learning statistics

# But wait...

Isn't R?
--------

# Confusing?
<p align="center"><img src="img/maze.jpg" height="590" width="750"></p>


# Buggy?
<p align="center"><img src="img/buggy.jpg" height="590" width="750"></p>

# How does Wisconsin use R?
- R is used to script repeated tasks and free up agency staff time for more policy research
- AYP, or accountability, is calculated using an R script that is reproducible, transparent, and fast!
- Other reports are being autmoated as well, and can continue through staff turnover
- Data quality can be standardized with basic data checking modules run before every report
- This leaves more time to do policy relevant research, which R has some great tools for

# How else is Wisconsin using R?
- Script common processes like AYP and other reports
- Fit growth models
- Visualize data for policy makers
- To build data indicators to use as discussions
- Analyze all sorts of ad hoc data from different sources, and combine datasets for quick policy questions

# Some Caveats
- A pretty picture **is not enough** 
- Good analysis **is still not enough**
- Need champions, policy makers, and decision makers who are willing to hear what the data **say**, what the data **cannot say**, and develop strategies to empirically investigate possible interventions/causes/policy relevant questions
- This is a tall order and one we haven't quite squared in Wisconsin just yet

# Thoughts
1. What are some ways inference trees could be used in your agency? 
2. What types of analyses would be useful across district and state agencies?
3. Sharing work with common data is something we all have an interest in to understand our work. How can we make this happen?

# Attribution and License
<p xmlns:dct="http://purl.org/dc/terms/">
<a rel="license" href="http://creativecommons.org/publicdomain/mark/1.0/">
<img src="http://i.creativecommons.org/p/mark/1.0/88x31.png"
     style="border-style: none;" alt="Public Domain Mark" />
</a>
<br />
This work (<span property="dct:title">Data Analysis in an SEA</span>, by <a href="www.jaredknowles.com" rel="dct:creator"><span property="dct:title">Jared E. Knowles</span></a>), in service of the <a href="http://www.dpi.wi.gov" rel="dct:publisher"><span property="dct:title">Wisconsin Department of Public Instruction</span></a>, is free of known copyright restrictions.
</p>
